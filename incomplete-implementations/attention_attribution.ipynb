{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Research course submission\n",
    "\n",
    "**Name:** Abhijith Sreesylesh Babu\n",
    "\n",
    "**Paper:** Self-Attention Attribution: Interpreting Information Interactions Inside Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpreting Information Interactions Inside Transformer\n",
    "\n",
    "In this paper, the authors study how the interaction between the tokens in a text input are affecting the predictions of a transformer model\n",
    "\n",
    "### Transformer models\n",
    "\n",
    "Transformer models are the most used models in the modern language models. They have the ability to understand the relationship between the input tokens using attention mechanism. Each layer of a transformer has multiple attention heads, each head containing a self attention matrix\n",
    "\n",
    "### Attribution in transformer models\n",
    "\n",
    "In a transformer model, every attention head is a (n x n) matrix where n is the number of tokens in the batch of input. This matrix shows the attention between all pairs of words in the input batch. The change in output of a model with respect to a change in its attention head gives the attribution of each attention.\n",
    "\n",
    "The attribution can be found by calculating gradients from backpropogation. Since integrated gradients are known to be a good method of attribution in sequential models, here we use similar methods to find the attribution of the attention head.\n",
    "\n",
    "By finding the attribution of each attention in attention head, we can understand the word interactions that contributed the most to the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhij\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\abhij\\AppData\\Local\\Temp\\ipykernel_7872\\2070156385.py:8: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython.display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    }
   ],
   "source": [
    "# importing necessary packages\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import os\n",
    "import contextlib\n",
    "from tqdm import tqdm\n",
    "from IPython.core.display import display, HTML\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model used in this experiment\n",
    "\n",
    "This paper is implemented in BERT model which is a transformer model that can be fine tuned to do various tasks. For simplicity, I used a model similar to BERT, namely bart-large-mnli which is already trained to do MNLI (multi-genre natural language inference). The bart model has 12 layers, with each layer having 16 attention heads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the model and tokenizer\n",
    "\n",
    "model_name = \"facebook/bart-large-mnli\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, output_attentions=True)\n",
    "\n",
    "# Setting the model to evaluation mode\n",
    "with open(os.devnull, 'w') as fnull:\n",
    "    with contextlib.redirect_stdout(fnull):\n",
    "        model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bart-large-mnli model\n",
    "\n",
    "The model takes 2 strings as parameters, and says whether the second string entails the first string, contradicts it, or is not related to the first string at all.\n",
    "\n",
    "Here I am taking an example where the second sentence follows the first sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'contradiction', 1: 'neutral', 2: 'entailment'}\n"
     ]
    }
   ],
   "source": [
    "# Finding the class labels of the model\n",
    "\n",
    "print(model.config.id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the input texts\n",
    "\n",
    "premise = \"John is very poor in science\"\n",
    "hypothesis = \"John failed in physics exam\"\n",
    "\n",
    "# Since our hypothesis is an entailment, setting the target class accordingly\n",
    "\n",
    "target_class = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorizing the text to pass them as input to the model\n",
    "\n",
    "input_vectors = tokenizer(premise, hypothesis, return_tensors=\"pt\")\n",
    "input_vectors = input_vectors[\"input_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the function to compute the integrated gradients\n",
    "\n",
    "def _compute_integrated_gradients(attention_matrix, embeddings, steps=5):\n",
    "\n",
    "    # Creating a baseline attention matrix\n",
    "    baseline = torch.zeros_like(attention_matrix)  # No attention baseline\n",
    "\n",
    "    # Interpolating between the baseline and the actual attention matrix\n",
    "    interpolated_attn = [(baseline + (float(i) / steps) * (attention_matrix - baseline)) for i in range(steps + 1)]\n",
    "    gradients = []\n",
    "    \n",
    "    # Computing the gradients for each interpolated attention matrix\n",
    "    for attn_head in interpolated_attn:\n",
    "        attn_head_ = attn_head.clone()\n",
    "\n",
    "        # Setting the gradients to be computed\n",
    "        embeddings.requires_grad_()\n",
    "        embeddings.retain_grad()\n",
    "        embeddings.retain_graph = True\n",
    "\n",
    "        # Forward pass to find loss\n",
    "        output = model.model.encoder(inputs_embeds=embeddings, attention_mask = attn_head_, return_dict=True)\n",
    "        class_logits = model.classification_head(output.last_hidden_state[:, 0, :])\n",
    "        loss = -1*class_logits[0, target_class]\n",
    "        \n",
    "        # Backward pass to compute gradients\n",
    "        loss.backward(retain_graph=True)\n",
    "        gradients.append(embeddings.grad.mean(dim=2))\n",
    "\n",
    "    # Integrating the gradients to get the attribution\n",
    "    avg_gradients = torch.mean(torch.stack(gradients), dim=0)\n",
    "    attributions = (attention_matrix - baseline) * avg_gradients\n",
    "    return attributions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the function to compute the attention attributions\n",
    "def compute_attention_attributions():\n",
    "\n",
    "    # generating embeddings of the inputs for forward and backward pass\n",
    "    embedding_layer = model.model.shared\n",
    "    embeddings = embedding_layer(input_vectors)\n",
    "    embeddings.requires_grad_()\n",
    "    embeddings.retain_grad()\n",
    "    \n",
    "    # Forward pass to get the attentions\n",
    "    output = model.model.encoder(inputs_embeds=embeddings, return_dict=True)\n",
    "    attentions = output.attentions\n",
    "        \n",
    "    # Compute attribution scores for the attentions\n",
    "    attributions = []\n",
    "    for layer_attention in attentions:\n",
    "        for at_head in tqdm(layer_attention[0]):\n",
    "            at_head = at_head.mean(dim=0) \n",
    "            at_head = at_head.unsqueeze(0) \n",
    "            head_attr = _compute_integrated_gradients(at_head, embeddings)\n",
    "            attributions.append(head_attr)\n",
    "\n",
    "    return attributions\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BartModel is using BartSdpaAttention, but `torch.nn.functional.scaled_dot_product_attention` does not support `output_attentions=True` or `layer_head_mask` not None. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation=\"eager\"` when loading the model.\n",
      "100%|██████████| 16/16 [00:36<00:00,  2.27s/it]\n",
      "100%|██████████| 16/16 [00:39<00:00,  2.49s/it]\n",
      "100%|██████████| 16/16 [00:42<00:00,  2.63s/it]\n",
      "100%|██████████| 16/16 [00:42<00:00,  2.68s/it]\n",
      "100%|██████████| 16/16 [00:39<00:00,  2.48s/it]\n",
      "100%|██████████| 16/16 [00:47<00:00,  3.00s/it]\n",
      "100%|██████████| 16/16 [00:48<00:00,  3.05s/it]\n",
      "100%|██████████| 16/16 [00:50<00:00,  3.18s/it]\n",
      "100%|██████████| 16/16 [00:49<00:00,  3.11s/it]\n",
      "100%|██████████| 16/16 [00:45<00:00,  2.86s/it]\n",
      "100%|██████████| 16/16 [00:48<00:00,  3.00s/it]\n",
      "100%|██████████| 16/16 [00:49<00:00,  3.08s/it]\n"
     ]
    }
   ],
   "source": [
    "attributions = compute_attention_attributions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalizing the attributions for ease of visualization\n",
    "\n",
    "def normalize_attributions(attributions):\n",
    "    attributions = np.array(attributions)\n",
    "    min_attr = attributions.min()\n",
    "    max_attr = attributions.max()\n",
    "    normalized = 255 * (attributions - min_attr) / (max_attr - min_attr + 1e-11)\n",
    "    return normalized.astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the attributions\n",
    "\n",
    "Here I visualize the attribution based on color. The more green the word are, they had more interactions with words that contributed to the output of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style='color:rgba(0,0, 0)'> John </span><span style='color:rgba(0,3, 0)'>  is </span><span style='color:rgba(0,0, 0)'>  very </span><span style='color:rgba(0,0, 0)'>  poor </span><span style='color:rgba(0,0, 0)'>  in </span><span style='color:rgba(0,3, 0)'>  science </span><span style='color:rgba(0,0, 0)'> John </span><span style='color:rgba(0,1, 0)'>  failed </span><span style='color:rgba(0,0, 0)'>  in </span><span style='color:rgba(0,1, 0)'>  physics </span><span style='color:rgba(0,0, 0)'>  exam </span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style='color:rgba(0,166, 0)'> John </span><span style='color:rgba(0,163, 0)'>  is </span><span style='color:rgba(0,162, 0)'>  very </span><span style='color:rgba(0,165, 0)'>  poor </span><span style='color:rgba(0,164, 0)'>  in </span><span style='color:rgba(0,170, 0)'>  science </span><span style='color:rgba(0,168, 0)'> John </span><span style='color:rgba(0,187, 0)'>  failed </span><span style='color:rgba(0,165, 0)'>  in </span><span style='color:rgba(0,162, 0)'>  physics </span><span style='color:rgba(0,162, 0)'>  exam </span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style='color:rgba(0,162, 0)'> John </span><span style='color:rgba(0,165, 0)'>  is </span><span style='color:rgba(0,179, 0)'>  very </span><span style='color:rgba(0,174, 0)'>  poor </span><span style='color:rgba(0,132, 0)'>  in </span><span style='color:rgba(0,200, 0)'>  science </span><span style='color:rgba(0,199, 0)'> John </span><span style='color:rgba(0,190, 0)'>  failed </span><span style='color:rgba(0,183, 0)'>  in </span><span style='color:rgba(0,165, 0)'>  physics </span><span style='color:rgba(0,184, 0)'>  exam </span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style='color:rgba(0,56, 0)'> John </span><span style='color:rgba(0,85, 0)'>  is </span><span style='color:rgba(0,83, 0)'>  very </span><span style='color:rgba(0,57, 0)'>  poor </span><span style='color:rgba(0,38, 0)'>  in </span><span style='color:rgba(0,107, 0)'>  science </span><span style='color:rgba(0,93, 0)'> John </span><span style='color:rgba(0,80, 0)'>  failed </span><span style='color:rgba(0,15, 0)'>  in </span><span style='color:rgba(0,59, 0)'>  physics </span><span style='color:rgba(0,66, 0)'>  exam </span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style='color:rgba(0,56, 0)'> John </span><span style='color:rgba(0,74, 0)'>  is </span><span style='color:rgba(0,79, 0)'>  very </span><span style='color:rgba(0,0, 0)'>  poor </span><span style='color:rgba(0,65, 0)'>  in </span><span style='color:rgba(0,74, 0)'>  science </span><span style='color:rgba(0,83, 0)'> John </span><span style='color:rgba(0,105, 0)'>  failed </span><span style='color:rgba(0,15, 0)'>  in </span><span style='color:rgba(0,65, 0)'>  physics </span><span style='color:rgba(0,62, 0)'>  exam </span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style='color:rgba(0,14, 0)'> John </span><span style='color:rgba(0,85, 0)'>  is </span><span style='color:rgba(0,82, 0)'>  very </span><span style='color:rgba(0,78, 0)'>  poor </span><span style='color:rgba(0,105, 0)'>  in </span><span style='color:rgba(0,34, 0)'>  science </span><span style='color:rgba(0,56, 0)'> John </span><span style='color:rgba(0,133, 0)'>  failed </span><span style='color:rgba(0,0, 0)'>  in </span><span style='color:rgba(0,49, 0)'>  physics </span><span style='color:rgba(0,61, 0)'>  exam </span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style='color:rgba(0,13, 0)'> John </span><span style='color:rgba(0,48, 0)'>  is </span><span style='color:rgba(0,46, 0)'>  very </span><span style='color:rgba(0,54, 0)'>  poor </span><span style='color:rgba(0,67, 0)'>  in </span><span style='color:rgba(0,22, 0)'>  science </span><span style='color:rgba(0,28, 0)'> John </span><span style='color:rgba(0,53, 0)'>  failed </span><span style='color:rgba(0,0, 0)'>  in </span><span style='color:rgba(0,45, 0)'>  physics </span><span style='color:rgba(0,28, 0)'>  exam </span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style='color:rgba(0,37, 0)'> John </span><span style='color:rgba(0,138, 0)'>  is </span><span style='color:rgba(0,86, 0)'>  very </span><span style='color:rgba(0,218, 0)'>  poor </span><span style='color:rgba(0,117, 0)'>  in </span><span style='color:rgba(0,58, 0)'>  science </span><span style='color:rgba(0,76, 0)'> John </span><span style='color:rgba(0,82, 0)'>  failed </span><span style='color:rgba(0,39, 0)'>  in </span><span style='color:rgba(0,100, 0)'>  physics </span><span style='color:rgba(0,0, 0)'>  exam </span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style='color:rgba(0,0, 0)'> John </span><span style='color:rgba(0,187, 0)'>  is </span><span style='color:rgba(0,81, 0)'>  very </span><span style='color:rgba(0,168, 0)'>  poor </span><span style='color:rgba(0,156, 0)'>  in </span><span style='color:rgba(0,83, 0)'>  science </span><span style='color:rgba(0,87, 0)'> John </span><span style='color:rgba(0,116, 0)'>  failed </span><span style='color:rgba(0,52, 0)'>  in </span><span style='color:rgba(0,140, 0)'>  physics </span><span style='color:rgba(0,69, 0)'>  exam </span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style='color:rgba(0,63, 0)'> John </span><span style='color:rgba(0,189, 0)'>  is </span><span style='color:rgba(0,113, 0)'>  very </span><span style='color:rgba(0,157, 0)'>  poor </span><span style='color:rgba(0,165, 0)'>  in </span><span style='color:rgba(0,146, 0)'>  science </span><span style='color:rgba(0,145, 0)'> John </span><span style='color:rgba(0,135, 0)'>  failed </span><span style='color:rgba(0,104, 0)'>  in </span><span style='color:rgba(0,171, 0)'>  physics </span><span style='color:rgba(0,112, 0)'>  exam </span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style='color:rgba(0,97, 0)'> John </span><span style='color:rgba(0,175, 0)'>  is </span><span style='color:rgba(0,131, 0)'>  very </span><span style='color:rgba(0,153, 0)'>  poor </span><span style='color:rgba(0,159, 0)'>  in </span><span style='color:rgba(0,157, 0)'>  science </span><span style='color:rgba(0,206, 0)'> John </span><span style='color:rgba(0,137, 0)'>  failed </span><span style='color:rgba(0,119, 0)'>  in </span><span style='color:rgba(0,171, 0)'>  physics </span><span style='color:rgba(0,125, 0)'>  exam </span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style='color:rgba(0,111, 0)'> John </span><span style='color:rgba(0,215, 0)'>  is </span><span style='color:rgba(0,120, 0)'>  very </span><span style='color:rgba(0,161, 0)'>  poor </span><span style='color:rgba(0,205, 0)'>  in </span><span style='color:rgba(0,197, 0)'>  science </span><span style='color:rgba(0,243, 0)'> John </span><span style='color:rgba(0,142, 0)'>  failed </span><span style='color:rgba(0,105, 0)'>  in </span><span style='color:rgba(0,184, 0)'>  physics </span><span style='color:rgba(0,139, 0)'>  exam </span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for idx, layer in enumerate(attributions):\n",
    "    if idx%16 != 0:\n",
    "        continue\n",
    "    # layer = layer.sum(dim=1)\n",
    "    layer = layer.detach().clone().numpy()\n",
    "    \n",
    "    norm_layer = normalize_attributions(layer)\n",
    "    # print(norm_layer)\n",
    "    html_string = \"\"\n",
    "    for index, val in enumerate(norm_layer[0]):\n",
    "        str_print = tokenizer.decode(input_vectors.numpy()[0][index])\n",
    "        if str_print[0] == \"<\":\n",
    "            continue\n",
    "        html_string += f\"<span style='color:rgba(0,{val}, 0)'> {str_print} </span>\"\n",
    "    # print(html_string)\n",
    "    display(HTML(html_string)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Masking the attentionheads based on its importance\n",
    "\n",
    "If the attribution provided by the attention head is smaller, they are making very less impact on the output of the model. So if we remove the attention heads with less importance, that wont make a big impact on accuracy of the model.\n",
    "\n",
    "Here the importance of attention head is the maximum value of all the attributions inside the attention head. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalizing the importance for ease of visualization\n",
    "\n",
    "def normalize_importance(imp):\n",
    "    imp_arr = np.array(imp)\n",
    "    min_imp = imp_arr.min()\n",
    "    max_imp = imp_arr.max()\n",
    "    normalized = 255 * (imp_arr - min_imp) / (max_imp - min_imp + 1e-11)\n",
    "    return normalized.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   1\n",
      "   0   0   1   0   1   0   1   1   0   3   1   1   1   1   1   1   1   1\n",
      "   1   2   2   2   1   3   2   3   3   3   3   4   7   7   5   8   5   9\n",
      "   6   6   6   7   6   7   7   9   9   8  10  10  13  11  11  11  13  10\n",
      "  16  16  13  14   9  14  20  12  16  18  17  17  18  19  17  17  15  22\n",
      "  26  23  21  17  20  20  27  23  28  36  21  43  34  42  33  42  35  44\n",
      "  40  41  34  34  27  22  25  27  23  16  24  35  28  22  17  34  20  28\n",
      "  49  39  54  23  45  31  32  36  44  55  44  48  49  52  53  24  36  40\n",
      "  42  43  21  42  26  27  27  27  34  65  32  34  48  45  49  19  46  93\n",
      "  53  69  60 172  77 113  82  52  41  55  76  89 156  70  35  35  98  60\n",
      " 146 216 253 136 137  66 218 199 137 208 118 135]\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "# Calculating the importance of attention heads and finding the threshold value\n",
    "importance_scores = []\n",
    "for attn_head in attributions:\n",
    "    max_val = max(attn_head[0])\n",
    "    importance_scores.append(max_val.item())\n",
    "importance_scores = normalize_importance(importance_scores)\n",
    "print(importance_scores)\n",
    "threshold_val = sorted(importance_scores)[int(len(importance_scores)*0.35)]\n",
    "print(threshold_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_importances = [importance_scores[i * 16:(i + 1) * 16] for i in range(12)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "mask = []\n",
    "threshold = threshold_val\n",
    "for layer in attention_importances:\n",
    "    layer_mask = []\n",
    "    for head in layer:\n",
    "        head_mask = head > threshold\n",
    "        head_mask = int(head_mask)\n",
    "        layer_mask.append(head_mask)\n",
    "    mask.append(layer_mask)\n",
    "\n",
    "\n",
    "for i in mask:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pruning the model based on the above mask will lead us to the important attention heads in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import types\n",
    "\n",
    "def prune_tree(model, mask):\n",
    "    encoder = model.model.encoder\n",
    "    layers = encoder.layers\n",
    "    for idx, layer in enumerate(layers):\n",
    "        attn_weights = layer.self_attn\n",
    "        original_forward = attn_weights.forward \n",
    "\n",
    "        def new_forward(self, hidden_states, attention_mask=None, head_mask=None, output_attentions=False):\n",
    "            outputs = original_forward(hidden_states, attention_mask)\n",
    "            attention_scores = outputs[0]\n",
    "\n",
    "            # Apply pruning mask\n",
    "            attention_scores = attention_scores * mask[idx].unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "            return (attention_scores,) + outputs[1:]\n",
    "        layer.self_attn.forward = types.MethodType(new_forward, layer.self_attn)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned_model = prune_tree(model, mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adversarial Attack\n",
    "\n",
    "The attention attribution method gives the pair of words that contributes most to the output of the model. If we use the same words in another situation, it can manipulate the model's output.\n",
    "\n",
    "One example given in the paper is [floods, iowa] and [ice, florida]. These pairs of words contradict each other. If we use them arbitarily in a entailment input, we might be able to manipulate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_set_1 = [\"ice\", \"florida\"]\n",
    "adv_set_2 = [\"floods\", \"iowa\"]\n",
    "\n",
    "premise_new = f\"Titanic {adv_set_1[0]} is a very sad {adv_set_1[1]} movie\"\n",
    "hypothesis_new = f\"It {adv_set_2[0]} rains heavily in {adv_set_2[1]} the summer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contradiction -0.0021725024562329054\n",
      "neutral -0.03944947198033333\n",
      "entailment 0.023743169382214546\n"
     ]
    }
   ],
   "source": [
    "# Creating the input vectors for the safe text\n",
    "\n",
    "input_vectors_new = tokenizer(premise_new, hypothesis_new, return_tensors=\"pt\")\n",
    "input_vectors_new = input_vectors_new[\"input_ids\"]\n",
    "embedding_layer_new = model.model.shared\n",
    "embeddings_new = embedding_layer_new(input_vectors_new)\n",
    "\n",
    "\n",
    "output = model.model.encoder(inputs_embeds=embeddings_new, return_dict=True)\n",
    "class_logits = model.classification_head(output.last_hidden_state[:, 0, :])\n",
    "class_labels = model.config.id2label\n",
    "for i in range(3):\n",
    "    print(class_labels[i],class_logits[0][i].item())\n",
    "    # print(i.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that even though the inputs are neutral, the model gave higher score for contradiction than neutral"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
